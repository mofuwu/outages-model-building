{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting money lost from outages\n",
    "\n",
    "**Name(s)**: Junyi Xu and Sean Chan\n",
    "\n",
    "**Website Link**: https://mofuwu.github.io/outages-model-building/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error # Built-in RMSE/MSE function.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSTAL.CODE</th>\n",
       "      <th>OUTAGE.START.DATE</th>\n",
       "      <th>OUTAGE.START.TIME</th>\n",
       "      <th>CAUSE.CATEGORY</th>\n",
       "      <th>OUTAGE.DURATION</th>\n",
       "      <th>DEMAND.LOSS.MW</th>\n",
       "      <th>RES.PRICE</th>\n",
       "      <th>COM.PRICE</th>\n",
       "      <th>IND.PRICE</th>\n",
       "      <th>RES.SALES</th>\n",
       "      <th>COM.SALES</th>\n",
       "      <th>IND.SALES</th>\n",
       "      <th>RES.PERCEN</th>\n",
       "      <th>COM.PERCEN</th>\n",
       "      <th>IND.PERCEN</th>\n",
       "      <th>RES.CUSTOMERS</th>\n",
       "      <th>COM.CUSTOMERS</th>\n",
       "      <th>IND.CUSTOMERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MN</td>\n",
       "      <td>2011-07-01 00:00:00</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>3060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.6</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.81</td>\n",
       "      <td>2332915</td>\n",
       "      <td>2114774</td>\n",
       "      <td>2113291</td>\n",
       "      <td>35.549073</td>\n",
       "      <td>32.225029</td>\n",
       "      <td>32.202431</td>\n",
       "      <td>2308736.0</td>\n",
       "      <td>276286.0</td>\n",
       "      <td>10673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN</td>\n",
       "      <td>2014-05-11 00:00:00</td>\n",
       "      <td>18:38:00</td>\n",
       "      <td>intentional attack</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.12</td>\n",
       "      <td>9.71</td>\n",
       "      <td>6.49</td>\n",
       "      <td>1586986</td>\n",
       "      <td>1807756</td>\n",
       "      <td>1887927</td>\n",
       "      <td>30.032487</td>\n",
       "      <td>34.210389</td>\n",
       "      <td>35.727564</td>\n",
       "      <td>2345860.0</td>\n",
       "      <td>284978.0</td>\n",
       "      <td>9898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "      <td>2010-10-26 00:00:00</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.87</td>\n",
       "      <td>8.19</td>\n",
       "      <td>6.07</td>\n",
       "      <td>1467293</td>\n",
       "      <td>1801683</td>\n",
       "      <td>1951295</td>\n",
       "      <td>28.097672</td>\n",
       "      <td>34.501015</td>\n",
       "      <td>37.365983</td>\n",
       "      <td>2300291.0</td>\n",
       "      <td>276463.0</td>\n",
       "      <td>10150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MN</td>\n",
       "      <td>2012-06-19 00:00:00</td>\n",
       "      <td>04:30:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>2550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.79</td>\n",
       "      <td>9.25</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1851519</td>\n",
       "      <td>1941174</td>\n",
       "      <td>1993026</td>\n",
       "      <td>31.994099</td>\n",
       "      <td>33.54333</td>\n",
       "      <td>34.439329</td>\n",
       "      <td>2317336.0</td>\n",
       "      <td>278466.0</td>\n",
       "      <td>11010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MN</td>\n",
       "      <td>2015-07-18 00:00:00</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>1740</td>\n",
       "      <td>250</td>\n",
       "      <td>13.07</td>\n",
       "      <td>10.16</td>\n",
       "      <td>7.74</td>\n",
       "      <td>2028875</td>\n",
       "      <td>2161612</td>\n",
       "      <td>1777937</td>\n",
       "      <td>33.982576</td>\n",
       "      <td>36.20585</td>\n",
       "      <td>29.779498</td>\n",
       "      <td>2374674.0</td>\n",
       "      <td>289044.0</td>\n",
       "      <td>9812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>ND</td>\n",
       "      <td>2011-12-06 00:00:00</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>public appeal</td>\n",
       "      <td>720</td>\n",
       "      <td>155</td>\n",
       "      <td>8.41</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>488853</td>\n",
       "      <td>438133</td>\n",
       "      <td>386693</td>\n",
       "      <td>37.212544</td>\n",
       "      <td>33.351628</td>\n",
       "      <td>29.435904</td>\n",
       "      <td>330738.0</td>\n",
       "      <td>60017.0</td>\n",
       "      <td>3639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fuel supply emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309997.0</td>\n",
       "      <td>53709.0</td>\n",
       "      <td>2331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29 00:00:00</td>\n",
       "      <td>22:54:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>59</td>\n",
       "      <td>84</td>\n",
       "      <td>9.25</td>\n",
       "      <td>7.47</td>\n",
       "      <td>5.53</td>\n",
       "      <td>337874</td>\n",
       "      <td>370771</td>\n",
       "      <td>215406</td>\n",
       "      <td>36.564432</td>\n",
       "      <td>40.124517</td>\n",
       "      <td>23.311051</td>\n",
       "      <td>367206.0</td>\n",
       "      <td>65971.0</td>\n",
       "      <td>3052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29 00:00:00</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>181</td>\n",
       "      <td>373</td>\n",
       "      <td>9.25</td>\n",
       "      <td>7.47</td>\n",
       "      <td>5.53</td>\n",
       "      <td>337874</td>\n",
       "      <td>370771</td>\n",
       "      <td>215406</td>\n",
       "      <td>36.564432</td>\n",
       "      <td>40.124517</td>\n",
       "      <td>23.311051</td>\n",
       "      <td>367206.0</td>\n",
       "      <td>65971.0</td>\n",
       "      <td>3052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>equipment failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230534.0</td>\n",
       "      <td>38074.0</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1534 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     POSTAL.CODE    OUTAGE.START.DATE OUTAGE.START.TIME  \\\n",
       "1             MN  2011-07-01 00:00:00          17:00:00   \n",
       "2             MN  2014-05-11 00:00:00          18:38:00   \n",
       "3             MN  2010-10-26 00:00:00          20:00:00   \n",
       "4             MN  2012-06-19 00:00:00          04:30:00   \n",
       "5             MN  2015-07-18 00:00:00          02:00:00   \n",
       "...          ...                  ...               ...   \n",
       "1530          ND  2011-12-06 00:00:00          08:00:00   \n",
       "1531          ND                  NaN               NaN   \n",
       "1532          SD  2009-08-29 00:00:00          22:54:00   \n",
       "1533          SD  2009-08-29 00:00:00          11:00:00   \n",
       "1534          AK                  NaN               NaN   \n",
       "\n",
       "             CAUSE.CATEGORY OUTAGE.DURATION DEMAND.LOSS.MW RES.PRICE  \\\n",
       "1            severe weather            3060            NaN      11.6   \n",
       "2        intentional attack               1            NaN     12.12   \n",
       "3            severe weather            3000            NaN     10.87   \n",
       "4            severe weather            2550            NaN     11.79   \n",
       "5            severe weather            1740            250     13.07   \n",
       "...                     ...             ...            ...       ...   \n",
       "1530          public appeal             720            155      8.41   \n",
       "1531  fuel supply emergency             NaN           1650       NaN   \n",
       "1532              islanding              59             84      9.25   \n",
       "1533              islanding             181            373      9.25   \n",
       "1534      equipment failure             NaN             35       NaN   \n",
       "\n",
       "     COM.PRICE IND.PRICE RES.SALES COM.SALES IND.SALES RES.PERCEN COM.PERCEN  \\\n",
       "1         9.18      6.81   2332915   2114774   2113291  35.549073  32.225029   \n",
       "2         9.71      6.49   1586986   1807756   1887927  30.032487  34.210389   \n",
       "3         8.19      6.07   1467293   1801683   1951295  28.097672  34.501015   \n",
       "4         9.25      6.71   1851519   1941174   1993026  31.994099   33.54333   \n",
       "5        10.16      7.74   2028875   2161612   1777937  33.982576   36.20585   \n",
       "...        ...       ...       ...       ...       ...        ...        ...   \n",
       "1530       7.8       6.2    488853    438133    386693  37.212544  33.351628   \n",
       "1531       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "1532      7.47      5.53    337874    370771    215406  36.564432  40.124517   \n",
       "1533      7.47      5.53    337874    370771    215406  36.564432  40.124517   \n",
       "1534       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "\n",
       "     IND.PERCEN  RES.CUSTOMERS  COM.CUSTOMERS  IND.CUSTOMERS  \n",
       "1     32.202431      2308736.0       276286.0        10673.0  \n",
       "2     35.727564      2345860.0       284978.0         9898.0  \n",
       "3     37.365983      2300291.0       276463.0        10150.0  \n",
       "4     34.439329      2317336.0       278466.0        11010.0  \n",
       "5     29.779498      2374674.0       289044.0         9812.0  \n",
       "...         ...            ...            ...            ...  \n",
       "1530  29.435904       330738.0        60017.0         3639.0  \n",
       "1531        NaN       309997.0        53709.0         2331.0  \n",
       "1532  23.311051       367206.0        65971.0         3052.0  \n",
       "1533  23.311051       367206.0        65971.0         3052.0  \n",
       "1534        NaN       230534.0        38074.0          854.0  \n",
       "\n",
       "[1534 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load outage data\n",
    "outage = pd.read_excel('outage.xlsx', skiprows=5, usecols=['POSTAL.CODE', 'CAUSE.CATEGORY', 'OUTAGE.DURATION', 'DEMAND.LOSS.MW', 'RES.PERCEN', 'COM.PERCEN', 'IND.PERCEN', 'RES.PRICE', 'COM.PRICE', 'IND.PRICE', 'RES.SALES', 'COM.SALES', 'IND.SALES', 'RES.CUSTOMERS', 'COM.CUSTOMERS', 'IND.CUSTOMERS', 'OUTAGE.START.DATE', 'OUTAGE.START.TIME'])\n",
    "outage = outage.drop(index=0)\n",
    "outage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning for Outages dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imputation and data cleaning below originally came from Project 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform probabilistic imputation on multiple columns together\n",
    "def multi_prob_impute(df, cols):\n",
    "    missingness = outage[cols[-1]].isna()\n",
    "    fill_index = np.random.choice(outage[cols[-1]].dropna().index, missingness.sum())\n",
    "    fill_values = outage.loc[fill_index, cols]\n",
    "    for col in cols:\n",
    "        df.loc[missingness, col] = fill_values[col].to_numpy()\n",
    "\n",
    "# perform probabilistic imputation on single column\n",
    "def single_prob_impute(df, col):\n",
    "    fill_values = np.random.choice(df[col].dropna(), df[col].isna().sum())\n",
    "    df.loc[df[col].isna(), col] = fill_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_imputate(df, col_category, sectors):\n",
    "    df = df.copy()\n",
    "    for category in col_category:\n",
    "        for sector in sectors:\n",
    "            col = '.'.join([sector, category])\n",
    "            single_prob_impute(df, col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sector(df, col_category, sectors):\n",
    "    df = df.copy() \n",
    "    for category in col_category:\n",
    "        cols = ['.'.join([sector, category]) for sector in sectors]\n",
    "        df[category] = df[cols].apply(lambda row: list(row.values), axis=1)\n",
    "        df = df.drop(columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_mean_impute(df, target, dependent):\n",
    "    return df.groupby(dependent)[target].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_col = ['POSTAL.CODE', 'OUTAGE.START.DATE', 'OUTAGE.START.TIME', 'CAUSE.CATEGORY']\n",
    "sector_related = ['PRICE', 'SALES', 'CUSTOMERS', 'MONEY.LOST']\n",
    "sectors = ['RES', 'COM', 'IND']\n",
    "\n",
    "outage_imputed = outage.copy()\n",
    "\n",
    "# use probabilistic imputation to fill missing values in sector related columns\n",
    "outage_imputed = prob_imputate(outage_imputed, sector_related[:-1], sectors)\n",
    "multi_prob_impute(outage_imputed, ['RES.PERCEN', 'IND.PERCEN', 'COM.PERCEN'])\n",
    "\n",
    "# use within-group mean imputation to fill missing values\n",
    "outage_imputed['OUTAGE.DURATION'] = conditional_mean_impute(outage_imputed, 'OUTAGE.DURATION', 'CAUSE.CATEGORY')\n",
    "outage_imputed['DEMAND.LOSS.MW'] = conditional_mean_impute(outage_imputed, 'DEMAND.LOSS.MW', 'CAUSE.CATEGORY')\n",
    "\n",
    "outage_imputed = outage_imputed[~outage_imputed['OUTAGE.START.DATE'].isna()]\n",
    "outage_imputed.loc[:, ~outage_imputed.columns.isin(non_numeric_col)] = outage_imputed.loc[:, ~outage_imputed.columns.isin(non_numeric_col)].astype(float)\n",
    "outage_imputed['OUTAGE.START.DATE'] = pd.to_datetime(outage_imputed['OUTAGE.START.DATE']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_lost(row, sector):\n",
    "    return round(row['OUTAGE.DURATION']*row[f'{sector}.PERCEN']*row['DEMAND.LOSS.MW']*row[f'{sector}.PRICE'] / 60000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSTAL.CODE</th>\n",
       "      <th>OUTAGE.START.DATE</th>\n",
       "      <th>OUTAGE.START.TIME</th>\n",
       "      <th>CAUSE.CATEGORY</th>\n",
       "      <th>OUTAGE.DURATION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>SALES</th>\n",
       "      <th>CUSTOMERS</th>\n",
       "      <th>MONEY.LOST</th>\n",
       "      <th>SECTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MN</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>11.60</td>\n",
       "      <td>2332915.0</td>\n",
       "      <td>2308736.0</td>\n",
       "      <td>13010.97</td>\n",
       "      <td>RES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MN</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2114774.0</td>\n",
       "      <td>276286.0</td>\n",
       "      <td>9333.82</td>\n",
       "      <td>COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>2113291.0</td>\n",
       "      <td>10673.0</td>\n",
       "      <td>6919.25</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "      <td>2014-05-11</td>\n",
       "      <td>18:38:00</td>\n",
       "      <td>intentional attack</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.12</td>\n",
       "      <td>1586986.0</td>\n",
       "      <td>2345860.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>RES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MN</td>\n",
       "      <td>2014-05-11</td>\n",
       "      <td>18:38:00</td>\n",
       "      <td>intentional attack</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.71</td>\n",
       "      <td>1807756.0</td>\n",
       "      <td>284978.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>22:54:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.47</td>\n",
       "      <td>370771.0</td>\n",
       "      <td>65971.0</td>\n",
       "      <td>24.76</td>\n",
       "      <td>COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>22:54:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>215406.0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>181.0</td>\n",
       "      <td>9.25</td>\n",
       "      <td>337874.0</td>\n",
       "      <td>367206.0</td>\n",
       "      <td>380.57</td>\n",
       "      <td>RES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>181.0</td>\n",
       "      <td>7.47</td>\n",
       "      <td>370771.0</td>\n",
       "      <td>65971.0</td>\n",
       "      <td>337.26</td>\n",
       "      <td>COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>SD</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>islanding</td>\n",
       "      <td>181.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>215406.0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>145.05</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4575 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     POSTAL.CODE OUTAGE.START.DATE OUTAGE.START.TIME      CAUSE.CATEGORY  \\\n",
       "0             MN        2011-07-01          17:00:00      severe weather   \n",
       "1             MN        2011-07-01          17:00:00      severe weather   \n",
       "2             MN        2011-07-01          17:00:00      severe weather   \n",
       "3             MN        2014-05-11          18:38:00  intentional attack   \n",
       "4             MN        2014-05-11          18:38:00  intentional attack   \n",
       "...          ...               ...               ...                 ...   \n",
       "4570          SD        2009-08-29          22:54:00           islanding   \n",
       "4571          SD        2009-08-29          22:54:00           islanding   \n",
       "4572          SD        2009-08-29          11:00:00           islanding   \n",
       "4573          SD        2009-08-29          11:00:00           islanding   \n",
       "4574          SD        2009-08-29          11:00:00           islanding   \n",
       "\n",
       "      OUTAGE.DURATION  PRICE      SALES  CUSTOMERS  MONEY.LOST SECTOR  \n",
       "0              3060.0  11.60  2332915.0  2308736.0    13010.97    RES  \n",
       "1              3060.0   9.18  2114774.0   276286.0     9333.82    COM  \n",
       "2              3060.0   6.81  2113291.0    10673.0     6919.25    IND  \n",
       "3                 1.0  12.12  1586986.0  2345860.0        0.06    RES  \n",
       "4                 1.0   9.71  1807756.0   284978.0        0.05    COM  \n",
       "...               ...    ...        ...        ...         ...    ...  \n",
       "4570             59.0   7.47   370771.0    65971.0       24.76    COM  \n",
       "4571             59.0   5.53   215406.0     3052.0       10.65    IND  \n",
       "4572            181.0   9.25   337874.0   367206.0      380.57    RES  \n",
       "4573            181.0   7.47   370771.0    65971.0      337.26    COM  \n",
       "4574            181.0   5.53   215406.0     3052.0      145.05    IND  \n",
       "\n",
       "[4575 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sector in sectors:\n",
    "    outage_imputed[f'{sector}.MONEY.LOST'] = outage_imputed.apply(lambda row: money_lost(row, sector), axis=1)\n",
    "\n",
    "outage_imputed = outage_imputed.drop(columns=['DEMAND.LOSS.MW', 'RES.PERCEN', 'COM.PERCEN', 'IND.PERCEN'])\n",
    "# print(outage.head().to_markdown())\n",
    "\n",
    "outage_merge = merge_sector(outage_imputed, sector_related, sectors)\n",
    "outage_explode = outage_merge.explode(sector_related).reset_index().drop(columns='index')\n",
    "outage_explode['SECTOR'] = sectors*len(outage_merge)\n",
    "outage_explode.loc[:, ['PRICE', 'SALES', 'CUSTOMERS', 'MONEY.LOST']] = outage_explode.loc[:, ['PRICE', 'SALES', 'CUSTOMERS', 'MONEY.LOST']].astype(float)\n",
    "outage_explode = outage_explode[outage_explode['MONEY.LOST'] < 2e6]\n",
    "display(outage_explode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "source": [
    "# TODO\n",
    "## Baseline model\n",
    "### Categorical features\n",
    "1. Cause cateogory\n",
    "2. Sector\n",
    "### Numerical features\n",
    "1. Average electricity consumption (sales)\n",
    "2. Duration\n",
    "3. Price\n",
    "4. Customers served\n",
    "\n",
    "\n",
    "## Final model\n",
    "### Categorical features\n",
    "1. Cause cateogory\n",
    "2. Date of time (Morning, Evening, Night)\n",
    "3. Date (Workday or weekend)\n",
    "4. Geographical region\n",
    "5. Sector\n",
    "\n",
    "### Numerical features\n",
    "1. Average electricity consumption (sales)\n",
    "2. Duration\n",
    "3. Price\n",
    "4. Customers served"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_train,  y_train), model\n",
    "\n",
    "def test(X_test, y_test, model):\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def baseline_model():\n",
    "    preproc = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('categorical_features', OneHotEncoder(), ['CAUSE.CATEGORY', 'SECTOR'])\n",
    "        ],\n",
    "        remainder = 'passthrough' \n",
    "    )\n",
    "\n",
    "    pl = Pipeline([\n",
    "        ('preprocessor', preproc),\n",
    "        ('lin-reg', LinearRegression())\n",
    "    ])\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.17180298336664357\n",
      "test score:  0.20517124605525375\n"
     ]
    }
   ],
   "source": [
    "total_train_score = total_test_score = 0\n",
    "num_iter = 100\n",
    "dropped_cols = ['POSTAL.CODE', 'OUTAGE.START.DATE', 'OUTAGE.START.TIME', 'MONEY.LOST']\n",
    "model = baseline_model()\n",
    "for i in range(num_iter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(outage_explode.drop(dropped_cols, axis=1), \n",
    "                                                        outage_explode['MONEY.LOST'], \n",
    "                                                        test_size=0.25)\n",
    "    score, model = train(X_train, y_train, model)\n",
    "    total_train_score += score\n",
    "    score = test(X_test, y_test, model)\n",
    "    total_test_score += score\n",
    "print('train score: ', total_train_score / num_iter)\n",
    "print('test score: ', total_test_score / num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "As the baseline model's test score is greater than its train score (0.20517124605525375 > 0.17180298336664357), this indicates that our model does not overfit and can generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(time):\n",
    "    if time >= datetime.time(5,0) and time < datetime.time(12, 0):\n",
    "        return 'Morning'\n",
    "    elif time >= datetime.time(12, 0) and time < datetime.time(17, 0):\n",
    "        return 'Afternoon'\n",
    "    elif time >= datetime.time(17, 0) and time < datetime.time(21, 0):\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "    \n",
    "us_region = {\"West\": ['CA', 'NV', 'UT', 'CO', 'WY', 'MT', 'ID', 'OR', 'WA', 'AK', 'HI'], \n",
    "             \"Southwest\": ['AZ', 'NM', 'TX', 'OK'], \n",
    "             \"Midwest\": ['ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'MI', 'IN', 'OH'], \n",
    "            \"Southeast\": ['AR', 'LA', 'MS', 'TN', 'AL', 'KY', 'GA', 'FL', 'NC', 'SC', 'VA', 'WV', 'DC', 'DE', 'MD'],\n",
    "            \"Northeast\": ['NY', 'PA', 'NJ', 'CT', 'RI', 'MA', 'VT', 'NH', 'ME']}\n",
    "def get_region(state):\n",
    "    for region in us_region.keys():\n",
    "        if state in us_region[region]:\n",
    "            return region\n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outage_trans = outage_explode.copy()\n",
    "\n",
    "outage_trans['IS.WEEKEND'] = outage_trans['OUTAGE.START.DATE'].apply(lambda d: d.weekday() > 4)\n",
    "outage_trans = outage_trans.drop(['OUTAGE.START.DATE'], axis=1)\n",
    "\n",
    "outage_trans['OUTAGE.START.TIME'] = outage_trans['OUTAGE.START.TIME'].apply(time_of_day)\n",
    "\n",
    "outage_trans['U.S.REGION'] = outage_trans['POSTAL.CODE'].apply(get_region)\n",
    "outage_trans = outage_trans.drop(['POSTAL.CODE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # X might not be a pandas DataFrame (e.g. a np.array)\n",
    "\n",
    "        # Compute and store the means/standard-deviations for each column (e.g. 'c1' and 'c2'), \n",
    "        # for each group (e.g. 'A', 'B', 'C').  \n",
    "        # (Our solution uses a dictionary)\n",
    "\n",
    "        X = pd.DataFrame(X)\n",
    "        self.grps_ = X.groupby(X.columns[0]).agg(['mean', 'std']).to_dict('index')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "        \n",
    "        # Hint: Define a helper function here!\n",
    "        def standardize_group(group_df):\n",
    "            group = group_df.iloc[0][group_df.columns[0]]\n",
    "            return group_df[group_df.columns[1:]].apply(lambda ser: standardize(ser, group, ser.name))\n",
    "\n",
    "        def standardize(ser, g, ser_name):\n",
    "            if (ser_name, 'mean') not in self.grps_[g].keys():\n",
    "                return np.full(len(ser), fill_value=np.nan)\n",
    "            mean = self.grps_[g][(ser_name, 'mean')]\n",
    "            std = self.grps_[g][(ser_name, 'std')]\n",
    "            return (ser - mean) / std\n",
    "\n",
    "        df = pd.DataFrame(X)\n",
    "        return df.groupby(df.columns[0]).apply(standardize_group).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Final Model\n",
    "For our final model, we decided to use ElasticNet regression, which is a similar linear regression model that combines \n",
    "L1 and L2 norm in loss function. Since the calculation of mean square error requires for loop whereas the calculation \n",
    "of L2 norm relies on matrix multiplication, ElasticNet regression can achieve higher computational efficiency.\n",
    "\n",
    "The hyperparameters we plan to tune are \"max_iter\", \"alpha\" and \"l1_ratio\". We chose \"max_iter\", \"alpha\", and \"l1_ratio\" because they all affect the score of the model (R^2) and need to be adjusted to the right combination in order to prevent under-fitting and over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model\n",
    "def final_model_tuning():\n",
    "    hyperparameters = {\"max_iter\": [300, 500, 600, 700, 800],\n",
    "                      \"alpha\": [0.3, 0.4, 0.5, 0.6, 0.8, 0.9, 1],\n",
    "                      \"l1_ratio\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]}\n",
    "\n",
    "\n",
    "    preproc = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('std-scaler', StdScalerByGroup(), ['SECTOR', 'OUTAGE.DURATION', 'SALES', 'CUSTOMERS']),\n",
    "            ('one-hot', OneHotEncoder(drop='first'), ['OUTAGE.START.TIME', 'CAUSE.CATEGORY', 'IS.WEEKEND', 'SECTOR', 'U.S.REGION'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    pl = Pipeline([\n",
    "        ('preprocessor', preproc),\n",
    "        ('grid-search', GridSearchCV(ElasticNet(), hyperparameters, scoring='r2', cv=3))\n",
    "    ])\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.16238486193192458\n",
      "test score:  0.2622639235536409\n",
      "best parameter {'alpha': 0.3, 'l1_ratio': 0.6, 'max_iter': 300}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(outage_trans.drop(['MONEY.LOST'], axis=1), outage_trans['MONEY.LOST'], test_size=0.25)\n",
    "tuning_model = final_model_tuning()\n",
    "tuning_model.fit(X_train, y_train)\n",
    "print('train score: ', tuning_model.score(X_train, y_train))\n",
    "print('test score: ', tuning_model.score(X_test, y_test))\n",
    "print('best parameter', tuning_model.named_steps['grid-search'].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    preproc = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('std-scaler', StdScalerByGroup(), ['SECTOR', 'OUTAGE.DURATION', 'SALES', 'CUSTOMERS']),\n",
    "            ('one-hot', OneHotEncoder(drop='first'), ['OUTAGE.START.TIME', 'CAUSE.CATEGORY', 'IS.WEEKEND', 'SECTOR', 'U.S.REGION'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    pl = Pipeline([\n",
    "        ('preprocessor', preproc),\n",
    "        ('elastic-reg', ElasticNet(alpha=0.3, l1_ratio=0.6, max_iter=300))\n",
    "    ])\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.17013430005249217\n",
      "test score:  0.22195186620978952\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(outage_trans.drop(['MONEY.LOST'], axis=1), outage_trans['MONEY.LOST'], test_size=0.25)\n",
    "total_train_score = total_test_score = 0\n",
    "num_iter = 50\n",
    "model = final_model()\n",
    "for i in range(num_iter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(outage_trans.drop(['MONEY.LOST'], axis=1), \n",
    "                                                        outage_trans['MONEY.LOST'], \n",
    "                                                        test_size=0.25)\n",
    "    score, model = train(X_train, y_train, model)\n",
    "    total_train_score += score\n",
    "    score = test(X_test, y_test, model)\n",
    "    total_test_score += score\n",
    "print('train score: ', total_train_score / num_iter)\n",
    "print('test score: ', total_test_score / num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "As the Final Model's test score is greater than its train score (0.22195186620978952 > 0.17013430005249217), this indicates that our model does not overfit and can generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "source": [
    "**Null Hypothesis**: The precision for the model in predicting money lost in residential sector is the same as the precision for the model in predicting money lost in other sector.\n",
    "\n",
    "**Alternative Hypothesis**: The precision for the model in predicting money lost in residential sector is different from the precision for the model in predicting money lost in other sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_R_square = lambda x: model.score(x.drop(['MONEY.LOST'], axis=1), x['MONEY.LOST'])\n",
    "\n",
    "R_square_diff = []\n",
    "observed = outage_trans.groupby('SECTOR').apply(get_R_square).diff().abs().iloc[-1]\n",
    "num_iter = 1000\n",
    "\n",
    "for _ in range(num_iter):\n",
    "    df = outage_trans.copy()\n",
    "    with_shuffled = df.assign(SECTOR=np.random.permutation(df['SECTOR']))\n",
    "    R_square_diff.append(with_shuffled.groupby('SECTOR').apply(get_R_square).diff().abs().iloc[-1])\n",
    "p_value = (R_square_diff > observed).mean()\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R_square_diff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mhistogram(pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mR_square_diff\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDifference in R-square value\u001b[39m\u001b[38;5;124m'\u001b[39m]), \n\u001b[1;32m      2\u001b[0m                    histnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                    title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of the difference in R-square values\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m                   )              \n\u001b[1;32m      5\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_vline(x\u001b[38;5;241m=\u001b[39mobserved, line_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'R_square_diff' is not defined"
     ]
    }
   ],
   "source": [
    "fig = px.histogram(pd.DataFrame(R_square_diff, columns=['Difference in R-square value']), \n",
    "                   histnorm='probability', \n",
    "                   title='Distribution of the difference in R-square values'\n",
    "                  )              \n",
    "fig.add_vline(x=observed, line_color='red')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
